{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TH MTLNet_DomainNet correction (NA).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"pH5nqDYSSREn","executionInfo":{"status":"ok","timestamp":1640193045640,"user_tz":0,"elapsed":3176,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["import os\n","import pickle\n","import torch\n","import sys\n","\n","from PIL import Image\n","from skimage.io import imread\n","from skimage.transform import resize\n","from matplotlib import pyplot as plt\n","from tabulate import tabulate"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwWcjokwiLXP","executionInfo":{"status":"ok","timestamp":1640193047356,"user_tz":0,"elapsed":1721,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}},"outputId":"a831b3a7-7d76-45c4-ecbc-2f8f0135a08e"},"source":["# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# fix the path\n","original_path = os.getcwd()\n","sys.path.append(os.path.join('.', '..'))\n","sys.path.append('/content/drive/My Drive/Deep_Learning_Project12/')\n","os.chdir(sys.path[-1])"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"PT_qAUOWYZ7_"},"source":["# Import Data and Wrangling"]},{"cell_type":"code","metadata":{"id":"8bTtSqvsijGj","executionInfo":{"status":"ok","timestamp":1640193048361,"user_tz":0,"elapsed":1009,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","data_files = os.listdir(\"Files\")\n","  \n","labels = pd.read_csv(\"Files/dermx_labels.csv\")\n","labels[\"image_path\"] = [os.path.join(os.getcwd(),\"Files\", \"images\", f\"{x}.jpeg\") for x in labels[\"image_id\"]]\n","labels.drop(columns = \"Unnamed: 0\", inplace = True)\n","\n","labels.dropna().reset_index(drop = True)\n","labels = pd.get_dummies(labels, columns = [\"area\"])\n","labels[\"open_comedo\"] = (labels[\"open_comedo\"] > 0).astype(int)\n","\n","features_target = pd.read_csv(\"Files/diseases_characteristics.csv\")\n","features_target.rename(columns={\"Unnamed: 0\":\"disease\"},inplace=True)\n","\n","# create on_hot for diagnosis and get features\n","one_hot = pd.get_dummies(labels[\"diagnosis\"])\n","one_hot_encoding = [list(x) for x in one_hot.values]\n","\n","labels[\"ts\"] = one_hot_encoding\n","\n","# get features as multi hot\n","features_touse = list(labels.columns[list(range(2,9)) + [10,11,12,13]])\n","labels[\"features\"] = labels.loc[:, features_touse].values.tolist()\n","\n","# map feature sequences to value\n","features_map = {}\n","for idx, feat in enumerate(labels[\"features\"].apply(tuple).unique()):\n","  features_map[str(feat)] = idx\n","\n","labels[\"features_label\"] = labels[\"features\"].apply(tuple).apply(str).map(features_map)\n","\n","# get domain\n","domain = pd.read_csv(\"Files/diseases_characteristics.csv\")\n","domain.rename(columns={\"Unnamed: 0\":\"diagnosis\"},inplace=True)\n","domain = pd.get_dummies(domain, columns = [\"area\"])\n","same_sort = [\"diagnosis\"] + features_touse\n","domain = domain[same_sort]  # same sorting\n","\n","domain_one_hot = pd.get_dummies(domain[\"diagnosis\"])\n","\n","domain_one_hot_encoding = [list(x) for x in domain_one_hot.values]\n","domain[\"ts\"] = domain_one_hot_encoding\n","feature_cols = domain.columns[1:12]\n","domain[\"features\"] = domain.loc[:,feature_cols].values.tolist()\n","\n","# add domain features (domain knowledge) to dataframe\n","tf = []\n","for i, row in labels.iterrows():\n","  disease = row[\"diagnosis\"]\n","  true_features = domain.loc[domain.diagnosis == disease].features.tolist()[0]\n","  tf.append(true_features)\n","labels[\"domain_features\"] = tf \n","\n","domain = domain.sort_values(by=\"diagnosis\").reset_index(drop=True)\n","\n","data = labels.copy()\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJsPsVJQueiJ","executionInfo":{"status":"ok","timestamp":1640193048362,"user_tz":0,"elapsed":8,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["def add_domain(df: pd.DataFrame):\n","  domain = pd.read_csv(\"Files/diseases_characteristics.csv\")\n","  domain.rename(columns={\"Unnamed: 0\":\"diagnosis\"},inplace=True)\n","  domain = pd.get_dummies(domain, columns = [\"area\"])\n","  same_sort = list(labels.columns[list(range(1,9)) + [10,11,12,13]])\n","  domain = domain[same_sort]  # same sorting\n","\n","  domain_one_hot = pd.get_dummies(domain[\"diagnosis\"])\n","\n","  domain_one_hot_encoding = [list(x) for x in domain_one_hot.values]\n","  domain[\"ts\"] = domain_one_hot_encoding\n","  feature_cols = domain.columns[1:12]\n","  domain[\"features\"] = domain.loc[:,feature_cols].values.tolist()\n","\n","  # add domain features (domain knowledge) to dataframe\n","  tf = []\n","  for i, row in df.iterrows():\n","    disease = row[\"diagnosis\"]\n","    true_features = domain.loc[domain.diagnosis == disease].features.tolist()[0]\n","    tf.append(true_features)\n","  df[\"domain_features\"] = tf \n","\n","  return df"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3xOA3mWSKf6"},"source":["# Some Useful Functions"]},{"cell_type":"code","source":["#@title \n","from HelperFunctions.project_utils import Tracker\n","from sklearn.utils import class_weight\n","import ast\n","\n","def add_no_match(df: pd.DataFrame):\n","  \n","  unique_data = [list(x) for x in set(tuple(x) for x in df.domain_features)]\n","\n","  app = []\n","  for i, row in df.iterrows():\n","    for x in unique_data:\n","      tmp_row = row.copy()\n","      if tmp_row[\"domain_features\"] == x:\n","        pass\n","      else:\n","        tmp_row[\"diagnosis\"] = \"no_match\"\n","        tmp_row[\"domain_features\"] = x\n","        app.append(tmp_row)\n","\n","  # Create new data frame\n","  updated_df=df.append(app,ignore_index=True)\n","  \n","  # Update targets \"ts\"\n","  updated_df.drop(columns=\"ts\")\n","  new_dummies = pd.get_dummies(updated_df[\"diagnosis\"])\n","  new_dummies = [list(x) for x in new_dummies.values]\n","  updated_df[\"ts\"] = new_dummies\n","\n","  return updated_df\n","\n","def unique_lists(data: list):\n","  return [list(x) for x in set(tuple(x) for x in data)]\n","\n","def map_domain_knowledge(df: pd.DataFrame):\n","  keys = df.diagnosis.unique().tolist()\n","  map = dict()\n","  for k in keys:\n","    map[k] = df.loc[data[\"diagnosis\"] == k].domain_features.tolist()[0]\n","  return map\n","\n","def plt_tracker(tracker: Tracker, num_epoch):\n","    plt.figure(figsize=(14,8))\n","    epoch_ticks = range(0,num_epoch + 1, 5)\n","\n","    # loss\n","    plt.subplot(1,2,1)\n","    plt.plot(tracker.train_iter, tracker.train_loss, label='Training loss')\n","    plt.plot(tracker.val_iter, tracker.val_loss, label='Validation loss')\n","    plt.title(\"Loss\")\n","    plt.ylabel(\"Loss\"), plt.xlabel(\"Epoch\")\n","    plt.xticks(epoch_ticks)\n","    plt.legend()\n","    plt.grid()\n","\n","    # acc\n","    plt.subplot(1,2,2)\n","    plt.plot(tracker.train_iter, tracker.train_acc, label='Training accuracy')\n","    plt.plot(tracker.val_iter, tracker.val_acc, label='Validation accuracy')\n","    plt.title(\"Accuracy\")\n","    plt.ylabel(\"Accuracy\"), plt.xlabel(\"Epoch\")\n","    plt.xticks(epoch_ticks)\n","    plt.legend()\n","    plt.grid()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def calc_multiclass_weights(df: pd.DataFrame, device):\n","  \n","  cls = sorted(df.diagnosis.unique())\n","  y = df.diagnosis.to_list()\n","  csw = class_weight.compute_class_weight('balanced', classes = cls, y = y)\n","  class_weights = torch.tensor(csw,dtype=torch.float).to(device)\n","\n","  return class_weights\n","\n","def feature_intersect(domain, features):\n","    dom_feat = np.asarray(domain)\n","    curr_feat = np.asarray(features)\n","    \n","    ones=np.intersect1d(np.where(dom_feat==1), np.where(curr_feat==1))\n","    intersect = np.zeros(len(dom_feat),dtype=int)\n","    intersect[ones] = 1\n","\n","    return intersect\n","\n","def read_splits(path):\n","  return pd.read_csv(path, converters={1:ast.literal_eval,\n","                                       2:ast.literal_eval})\n"],"metadata":{"id":"d3biHzE1D6B1","executionInfo":{"status":"ok","timestamp":1640193049242,"user_tz":0,"elapsed":887,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aLn-nvWGYoNP"},"source":["# Define Dataset Class for features\n"]},{"cell_type":"code","metadata":{"id":"M0pDmn7JEFsI","executionInfo":{"status":"ok","timestamp":1640193049989,"user_tz":0,"elapsed":753,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["from tqdm import tqdm\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","\n","class DomainDatset(Dataset):\n","  def __init__(self, data: pd.DataFrame, augment=True):\n","    \n","    dictator = \"features_label\"\n","    if augment:\n","      sample_count = {}\n","      up_sampler = np.unique(data[dictator])\n","      for f in up_sampler:\n","          sample_count[f] = np.count_nonzero(data[dictator] == f)\n","\n","      maxcount = np.max(list(sample_count.values()))\n","      for f in up_sampler:\n","          gapnum = maxcount - sample_count[f]\n","          temp_df = data.iloc[np.random.choice(np.where(data[dictator] == f)[0], size = gapnum)]\n","          data = data.append(temp_df, ignore_index = True)\n","\n","    self.dataframe = data\n","\n","    self.data_input = data[\"features\"].reset_index(drop=True)\n","    self.domain_input = data[\"domain_features\"].reset_index(drop=True)\n","    self.target = data[\"ts\"].reset_index(drop=True)\n","\n","  def __len__(self):\n","    return (len(self.data_input))\n","\n","  def __getitem__(self, i):\n","    \n","    target = self.target[i]\n","    \n","    domain_input = self.domain_input[i]\n","    data_input = self.data_input[i]\n","    \n","    #input = [*data_input, *domain_input] \n","    #input = feature_intersect(domain_input, data_input)\n","    input = np.array(domain_input) + np.array(data_input)\n","\n","    return torch.tensor(input, dtype=torch.float), torch.tensor(target, dtype=torch.long)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LurTBO7TcaOu"},"source":["# Model `DomainNet` for learning Domain Knowledge"]},{"cell_type":"code","metadata":{"id":"dlfwKmSGFSjG","executionInfo":{"status":"ok","timestamp":1640193049990,"user_tz":0,"elapsed":12,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["# create the MTL network\n","from torch import nn\n","from torch import optim\n","import torchvision.models as models\n","\n","\n","class DomainNet(nn.Module):\n","\n","    def __init__(self, num_classes, num_features, num_hidden = 256):\n","        super(DomainNet, self).__init__()\n","\n","        self.num_classes = num_classes\n","        self.num_features = num_features\n","        \n","        self.layer_1 = nn.Sequential(\n","            nn.Linear(in_features=num_features, out_features=num_hidden),\n","            nn.ReLU(),\n","        )\n","\n","        self.layer_2 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(in_features=num_hidden, out_features=num_classes)\n","        )\n","\n","        # self.layer_2 = nn.Sequential(\n","        #     nn.Dropout(0.5),\n","        #     nn.Linear(in_features=num_hidden, out_features=num_hidden),\n","        #     nn.ReLU()\n","        # )\n","\n","        # self.layer_3 = nn.Sequential(\n","        #     nn.Dropout(0.5),\n","        #     nn.Linear(in_features=num_hidden, out_features=num_classes)\n","        # )\n","\n","    def forward(self, x):\n","\n","      x = self.layer_1(x)\n","\n","      x = self.layer_2(x)\n","\n","      # x = self.layer_3(x)\n","\n","      return x\n","    "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4TD9nUlmJ9Sr"},"source":["# Dataset for MTL Net\n"]},{"cell_type":"code","metadata":{"id":"E2SQGzYauEAt","executionInfo":{"status":"ok","timestamp":1640193049991,"user_tz":0,"elapsed":12,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["from tqdm import tqdm\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","\n","class NaturalImageDataset(Dataset):\n","  def __init__(self, data, augment = False, load_img=True, dictator=\"features_label\"):\n","\n","    dictator = 'features_label'    # What variable we use to upsample to match\n","    # upsample if augment\n","    if augment:\n","      sample_count = {}\n","      up_sampler = np.unique(data[dictator])\n","      for f in up_sampler:\n","          sample_count[f] = np.count_nonzero(data[dictator] == f)\n","\n","      maxcount = np.max(list(sample_count.values()))\n","      for f in up_sampler:\n","          gapnum = maxcount - sample_count[f]\n","          temp_df = data.iloc[np.random.choice(np.where(data[dictator] == f)[0], size = gapnum)]\n","          data = data.append(temp_df, ignore_index = True)\n","      \n","\n","    self.dataframe = data\n","    self.imgage_path = data[\"image_path\"].values\n","    self.labels = data[\"ts\"].values\n","    self.features = data[\"features\"].values\n","\n","    # transform image\n","    if augment:\n","      self.transform = transforms.Compose([\n","                                  transforms.Resize(256),\n","                                  transforms.CenterCrop(224),\n","                                  transforms.ToTensor(),\n","                                  transforms.RandomHorizontalFlip(p = 0.5),\n","                                  transforms.RandomVerticalFlip(p=0.5),\n","                                  transforms.ColorJitter(brightness = 0.1, contrast = 0.1),\n","                                  transforms.RandomAffine(degrees = 50, translate = (0.1, 0.1), scale = (0.9, 1.1)),\n","                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","                              ])\n","    else:\n","      self.transform = transforms.Compose([\n","                                  transforms.Resize(256),\n","                                  transforms.CenterCrop(224),\n","                                  transforms.ToTensor(),\n","                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","                              ])\n","\n","\n","    if load_img:\n","      self.images = [self.transform(Image.open(img_path)) for img_path in tqdm(data[\"image_path\"])]\n","\n","  def __len__(self):\n","    return (len(self.images))\n","\n","  def __getitem__(self, i):\n","    image = self.images[i]\n","    label = self.labels[i]\n","    feature = self.features[i]\n","    return image, torch.tensor(label, dtype=torch.long), torch.tensor(feature, dtype=torch.long)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4d5tf9Lpeneb"},"source":["# Model `MTLNet`"]},{"cell_type":"code","metadata":{"id":"5KXLFKxSesdy","executionInfo":{"status":"ok","timestamp":1640193049992,"user_tz":0,"elapsed":13,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["# create the MTL network\n","from torch import nn\n","from torch import optim\n","import torchvision.models as models\n","\n","class MTLNet(nn.Module):\n","    def __init__(self, num_classes, num_features):\n","        super(MTLNet, self).__init__()\n","\n","        self.num_classes = num_classes\n","        self.num_features = num_features\n","\n","        # modify resnet\n","        base_net = models.resnet50(pretrained=True)\n","\n","        # Freeze all parameters of base network\n","        for param in base_net.parameters():\n","          param.requires_grad = False\n","\n","        # Freeze all parameters of base network\n","        for param in base_net.layer4.parameters():\n","          param.requires_grad = True\n","\n","        # Unfreeze all bn params\n","        for module in base_net.modules():\n","          if isinstance(module, nn.BatchNorm2d):\n","            for param in module.parameters():\n","              param.requires_grad = True\n","                \n","\n","        # get head infeatures\n","        head_in = base_net.fc.in_features\n","        \n","        # Exclude fc layer\n","        base_layers = list(base_net.children())\n","        base_net = nn.Sequential(*base_layers[:-1])\n","\n","        # construct the base model\n","        self.base_model = nn.Sequential(\n","            base_net\n","        )\n","\n","        # labels head part\n","        self.labels_head = nn.Sequential(\n","            nn.Dropout(p=0.5),\n","            nn.Flatten(),\n","            nn.Linear(in_features = head_in, out_features = num_classes, bias=True),\n","\n","        )\n","\n","        # labels head part\n","        self.features_head = nn.Sequential(\n","            nn.Dropout(p=0.3),\n","            nn.Flatten(),\n","            nn.Linear(in_features = head_in, out_features = num_features, bias=True)\n","        )\n","\n","\n","    def forward(self, x):\n","\n","        # common part\n","        x = self.base_model(x)\n","        \n","        # # flatten dimensions\n","        # x = torch.flatten(x, 1) \n","\n","        # labels head part\n","        x_labels = self.labels_head(x)\n","\n","        # features head part\n","        x_features = self.features_head(x)\n","\n","        return x_labels, x_features\n","    "],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Mvhdd2bc-h3"},"source":["# Define train loop for `DomainNet`"]},{"cell_type":"code","metadata":{"id":"MbABx60HiPFR","executionInfo":{"status":"ok","timestamp":1640193050490,"user_tz":0,"elapsed":510,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["# Train the net\n","from HelperFunctions.project_utils import Tracker, plot_tracker\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def train_domain_net(net: DomainNet, criterion, optimizer, device,\n","                     trainloader: DataLoader, validationloader: DataLoader = None,\n","                     validation_on: bool = False, num_epoch = 100, eval_every = 3,\n","                     plt_on: bool = False):\n","\n","  # Initialize tracker\n","  tracker = Tracker()\n","\n","  for epoch in range(num_epoch):  \n","    #print(\"\\r\",end=f\"Epoch: {epoch}\", flush=True)\n","    # Train\n","    net.train()\n","    for i, x in enumerate(trainloader):\n","      input_batch, targets = x\n","      input_batch, targets = input_batch.to(device), targets.to(device)\n","\n","      output = net(input_batch)\n","\n","      # labels ------------------------------------------------------------\n","      true_class = torch.argmax(targets,dim=1)\n","      probabilities = nn.functional.softmax(output, dim = 1) \n","      preds = torch.argmax(probabilities,dim=1)\n","      \n","      loss = criterion(output, true_class)\n","      tracker.batch_loss.append(loss.item() / input_batch.size(0))\n","\n","      acc = f1_score(true_class.cpu(), preds.cpu(), average='weighted')\n","      tracker.batch_acc.append(acc)\n","\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()  \n","\n","    # Update training values with batch results\n","    tracker.train_update(epoch)\n","\n","    # Validate\n","    if validation_on & ((epoch % eval_every == 0) | (epoch == num_epoch - 1)):\n","      net.eval() \n","      with torch.no_grad(): \n","\n","        for i, v in enumerate(validationloader):\n","    \n","          input_batch, targets = x\n","          input_batch, targets = input_batch.to(device), targets.to(device)\n","\n","          output = net(input_batch)\n","\n","          true_class = torch.argmax(targets,dim=1)\n","          probabilities = nn.functional.softmax(output, dim = 1) \n","          preds = torch.argmax(probabilities,dim=1)\n","          \n","          loss = criterion(output, true_class)\n","          tracker.batch_loss.append(loss.item() / input_batch.size(0))\n","\n","          acc = f1_score(true_class.cpu(), preds.cpu(), average=\"weighted\")\n","          tracker.batch_acc.append(acc)\n","\n","      tracker.val_update(epoch)\n","\n","  if plt_on: plt_tracker(tracker, num_epoch)\n","  return tracker\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mTh0FBwLRpaF"},"source":["# Test `DomainNet`\n","\n"]},{"cell_type":"code","metadata":{"id":"kPasJgbYxmei","executionInfo":{"status":"ok","timestamp":1640193050491,"user_tz":0,"elapsed":16,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"source":["\n","def test_domain_net(net: DomainNet, testloader: DataLoader, device):\n","\n","  test_probs = []\n","  test_preds = []\n","  test_targets = []\n","\n","  for i, x in enumerate(testloader):\n","      input_batch, one_hot_target = x\n","      input_batch = input_batch.to(device)\n","\n","      output = net(input_batch)\n","\n","      targets = torch.argmax(one_hot_target,dim=1)\n","      probs = nn.functional.softmax(output, dim = 1) \n","      preds = torch.argmax(probs,dim=1)\n","\n","      test_probs = [*test_probs, *probs.cpu().detach().numpy()]\n","      test_preds = [*test_preds, *preds.cpu().detach().numpy()]\n","      test_targets = [*test_targets, *targets.cpu().detach().numpy()]\n","\n","      return {\"probs\": test_probs, \"preds\": test_preds, \"targets\": test_targets}\n","\n","    "],"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"DtT46qQi_Cgo"}},{"cell_type":"code","source":["def plot_conf(conf,target_labels):\n","  df_cm = pd.DataFrame(conf, index = [i for i in target_labels],\n","                              columns = [i for i in target_labels])\n","  plt.figure(figsize = (7,4))\n","  sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n","  plt.show()\n","\n","\n","# apply domain knowledge\n","def get_domain_probabilites(mtl_features, domain: pd.DataFrame):\n","  \n","  d_probs = np.zeros(shape=(NUM_CLASSES,NUM_CLASSES))\n","  \n","  for i, row in domain.iterrows():\n","    dom_feat = row.features\n","    \n","    #inp = torch.Tensor([*mtl_features, *dom_feat]).to(device)\n","    #inp = feature_intersect(domain = dom_feat, features = mtl_features)  # THIS!!!\n","    inp = torch.Tensor(np.array(dom_feat) + np.array(mtl_features)).to(device)\n","\n","    output = domain_net(inp)\n","    curr_prob = nn.functional.softmax(output, dim = 0)\n","    d_probs[i] = curr_prob.cpu().detach().numpy()\n","\n","  #plot_conf(d_probs,domain.diagnosis.values)\n","  return d_probs\n","\n","def apply_domain_correction(mtl_probs, mtl_features, domain: pd.DataFrame):\n","\n","  if max(mtl_probs) <= 1.0:\n","\n","    domain_probs = get_domain_probabilites(mtl_features, domain)\n","    #domain_probs = np.diag(domain_probs)\n","    domain_probs = np.sum(domain_probs,axis=0)\n","\n","    combined_probs = mtl_probs * domain_probs\n","\n","    corrected_prediction = combined_probs.argmax(axis=0)\n","    corrected_prediciton_prob = combined_probs[corrected_prediction]\n","\n","  else:\n","    return mtl_probs.argmax(axis=0), mtl_probs  \n","\n","  return corrected_prediction, domain_probs.argmax(axis=0)"],"metadata":{"id":"w2Pxs39c_Ecy","executionInfo":{"status":"ok","timestamp":1640193050491,"user_tz":0,"elapsed":15,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Check corrections"],"metadata":{"id":"JoCk7rz_kr-K"}},{"cell_type":"code","source":["from HelperFunctions.project_utils import KFoldResult\n","from sklearn.metrics import classification_report\n","import seaborn as sns\n","\n","\n","corr_results = []\n","corr_counts = np.zeros(shape=(5,6))\n","corr_f1 = []\n","mtl_f1 = []\n","\n","test_len=[]\n","\n","k = 5\n","for i in range(k):\n","\n","  target_labels = sorted(data.diagnosis.unique())\n","\n","  # COLLECT RUN VARIABLES\n","  k_name = f\"K_fold/Correction_FINAL_kfold_NA_{i}.json\"\n","  res = KFoldResult(k_name)\n","  test_len.append(len(res.test_idx))\n","  true_labels = res.test_labels_targets\n","  true_features = res.test_features_targets\n","\n","  mtl_probs = res.labels_probs.numpy()\n","  mtl_preds = res.labels_preds\n","  corrected_preds = res.corrected_preds\n","\n","  # Cast to np.array \n","  correction_preds = np.array(corrected_preds)\n","  change = (mtl_preds!=correction_preds).astype(int)\n","\n","  corr_df = pd.DataFrame()\n","  corr_df[\"disease\"] = [target_labels[x] for x in true_labels]  # Targets as labels\n","  corr_df[\"target\"] = true_labels                               # Targets as [0/1]\n","  corr_df[\"mtl_pred\"] = mtl_preds                               # MTL predictions\n","  corr_df[\"corrected_pred\"] = correction_preds                  # Correction prediction\n","  corr_df[\"change\"] = change                                    # Did it change? [0/1]\n","\n","  # Collect change effects:\n","\n","  # CORRECT => CORRECT (GOOD)   [CHANGE = 0] (correct_nochange)   - TTnC\n","  # WRONG   => CORRECT (GOOD)   [CHANGE = 1] (correct_change)     - FTC\n","  # CORRECT => WRONG (BAD)      [CHANGE = 1] (incorrect_change)   - TFC\n","  # WRONG   => WRONG (BAD)      [CHANGE = 1] (incorrect_change)   - FFC\n","  # WRONG   => SAME  (BAD)      [CHANGE = 0] (incorrect_nochange) - FFnC\n","\n","\n","  corr_df[\"TTnC\"] = ((mtl_preds == true_labels) & (correction_preds == true_labels) & (change==0)).astype(int)\n","  corr_df[\"FTC\"]  = ((mtl_preds != true_labels) & (correction_preds == true_labels) & (change==1)).astype(int)\n","  corr_df[\"TFC\"]  = ((mtl_preds == true_labels) & (correction_preds != true_labels) & (change==1)).astype(int)\n","  corr_df[\"FFC\"]  = ((mtl_preds != true_labels) & (correction_preds != true_labels) & (change==1)).astype(int)\n","  corr_df[\"FFnC\"]  = ((mtl_preds != true_labels) & (correction_preds != true_labels) & (change==0)).astype(int)\n","\n","\n","\n","  total = corr_df.agg({\"change\": \"sum\",\n","                       \"TTnC\": \"sum\",\n","                        \"FTC\": \"sum\",\n","                        \"TFC\": \"sum\",\n","                        \"FFC\": \"sum\",\n","                        \"FFnC\": \"sum\"})\n","\n","\n","  corr_results.append(corr_df)\n","  corr_counts[i] = total.values\n","  corr_f1.append(f1_score(true_labels, correction_preds,average=\"weighted\"))\n","  mtl_f1.append(f1_score(true_labels, mtl_preds,average=\"weighted\"))\n","  \n","corr_df = pd.DataFrame(data=corr_counts, columns=[\"Change\",\"TTnC\",\"FTC\",\"TFC\",\"FFC\",\"FnC\"])\n","corr_df[\"F1 MTL\"] = mtl_f1\n","corr_df[\"F1 Correction\"] = corr_f1\n","\n","tab=tabulate(corr_df,headers=corr_df.columns.to_list(),tablefmt=\"latex_raw\",floatfmt=\".2f\")\n","print(tab)\n","\n","# print(corr_counts.sum(axis=0))\n","print(\"\\nMean and std:\")\n","print(tabulate({\n","    \" \": [\"MTL\", \"Correction\"],\n","    \"mean\": [np.mean(mtl_f1), np.mean(corr_f1)],\n","    \"std\": [np.std(mtl_f1), np.std(corr_f1)]\n","}, headers = \"keys\", floatfmt=\".2f\"))\n","# print(np.mean(mtl_f1))\n","# print(np.std(mtl_f1))\n","# print(np.mean(corr_f1))\n","# print(np.std(corr_f1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMCDE6vnlfeT","executionInfo":{"status":"ok","timestamp":1640195452950,"user_tz":0,"elapsed":657,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}},"outputId":"afe837cf-9f86-41c8-910c-e2aa22e24cf3"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\\begin{tabular}{rrrrrrrrr}\n","\\hline\n","    &   Change &   TTnC &   FTC &   TFC &   FFC &   FnC &   F1 MTL &   F1 Correction \\\\\n","\\hline\n","  0 &     2.00 &  65.00 &  2.00 &  0.00 &  0.00 & 24.00 &     0.71 &            0.73 \\\\\n","  1 &     2.00 &  66.00 &  0.00 &  2.00 &  0.00 & 23.00 &     0.74 &            0.72 \\\\\n","  2 &     4.00 &  67.00 &  2.00 &  2.00 &  0.00 & 20.00 &     0.75 &            0.76 \\\\\n","  3 &     1.00 &  72.00 &  0.00 &  0.00 &  1.00 & 17.00 &     0.80 &            0.80 \\\\\n","  4 &     4.00 &  65.00 &  3.00 &  1.00 &  0.00 & 21.00 &     0.73 &            0.75 \\\\\n","\\hline\n","\\end{tabular}\n","\n","Mean and std:\n","              mean    std\n","----------  ------  -----\n","MTL           0.75   0.03\n","Correction    0.75   0.03\n"]}]},{"cell_type":"code","source":["cts = corr_df[corr_df.columns.to_list()[:-2]].to_numpy()\n","lens = np.array(test_len)\n","# print(cts)\n","# print(cts.transpose())\n","perc=cts.transpose()/lens\n","perc=perc.transpose()\n","\n","# print(perc)\n","# print(perc.transpose()) \n","mp = perc.mean(axis=0)\n","sd = perc.std(axis=0)\n","d = pd.DataFrame(perc, columns=corr_df.columns.to_list()[:-2])\n","tab=tabulate(perc,headers=d.columns.to_list())\n","print(tab)\n","print(\"\\nmean:\")\n","print(np.round(mp*100,2))\n","print(\"std:\")\n","print(sd*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QISsOGzasl8Y","executionInfo":{"status":"ok","timestamp":1640194204367,"user_tz":0,"elapsed":444,"user":{"displayName":"þorvaldur Ingi Ingimundarson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07092184877997916376"}},"outputId":"e93be699-5e0e-456b-e806-519f8b35c173"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["   Change      TTnC        FTC        TFC        FFC       FnC\n","---------  --------  ---------  ---------  ---------  --------\n","0.021978   0.714286  0.021978   0          0          0.263736\n","0.021978   0.725275  0          0.021978   0          0.252747\n","0.043956   0.736264  0.021978   0.021978   0          0.21978\n","0.0111111  0.8       0          0          0.0111111  0.188889\n","0.0444444  0.722222  0.0333333  0.0111111  0          0.233333\n","\n","mean:\n","[ 2.87 73.96  1.55  1.1   0.22 23.17]\n","std:\n","[1.32693119 3.10074312 1.32849422 0.98289916 0.44444444 2.62558534]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"bZp8rvuGG1-D"},"execution_count":null,"outputs":[]}]}